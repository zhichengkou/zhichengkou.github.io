<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"zhichengkou.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="论文《Learning Safety in Model-Based Reinforcement Learning using MPC and Gaussian Processes》提出了一种结合模型预测控制 (MPC) 和高斯过程 (GP) 回归的安全强化学习 (RL) 方法。以下是论文的核心内容分析：  背景与动机:  现代机器学习结合MPC已成为提高控制系统性能和安全性的重要方向。">
<meta property="og:type" content="article">
<meta property="og:title" content="safe learning实践 - 基于强化学习的MPC">
<meta property="og:url" content="http://zhichengkou.github.io/2025/03/18/safe-learning%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84MPC/index.html">
<meta property="og:site_name" content="Zhicheng">
<meta property="og:description" content="论文《Learning Safety in Model-Based Reinforcement Learning using MPC and Gaussian Processes》提出了一种结合模型预测控制 (MPC) 和高斯过程 (GP) 回归的安全强化学习 (RL) 方法。以下是论文的核心内容分析：  背景与动机:  现代机器学习结合MPC已成为提高控制系统性能和安全性的重要方向。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-03-18T12:50:59.000Z">
<meta property="article:modified_time" content="2025-04-07T11:53:33.706Z">
<meta property="article:author" content="Zhicheng">
<meta property="article:tag" content="强化学习">
<meta property="article:tag" content="MPC">
<meta property="article:tag" content="safe_learning">
<meta property="article:tag" content="控制">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://zhichengkou.github.io/2025/03/18/safe-learning%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84MPC/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>safe learning实践 - 基于强化学习的MPC | Zhicheng</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zhicheng</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container"></div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="algolia-results">
  <div id="algolia-stats"></div>
  <div id="algolia-hits"></div>
  <div id="algolia-pagination" class="algolia-pagination"></div>
</div>

      
    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://zhichengkou.github.io/2025/03/18/safe-learning%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84MPC/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/cheng.gif">
      <meta itemprop="name" content="Zhicheng">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhicheng">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          safe learning实践 - 基于强化学习的MPC
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-03-18 20:50:59" itemprop="dateCreated datePublished" datetime="2025-03-18T20:50:59+08:00">2025-03-18</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-04-07 19:53:33" itemprop="dateModified" datetime="2025-04-07T19:53:33+08:00">2025-04-07</time>
              </span>

          
            <span id="/2025/03/18/safe-learning%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84MPC/" class="post-meta-item leancloud_visitors" data-flag-title="safe learning实践 - 基于强化学习的MPC" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>论文《Learning Safety in Model-Based Reinforcement Learning using MPC
and Gaussian Processes》提出了一种结合模型预测控制 (MPC) 和高斯过程 (GP)
回归的安全强化学习 (RL) 方法。以下是论文的核心内容分析：</p>
<ol type="1">
<li><strong>背景与动机</strong>:
<ul>
<li>现代机器学习结合MPC已成为提高控制系统性能和安全性的重要方向。然而，大多数RL算法是基于模型无关的方法，缺乏对系统动态的充分了解，容易导致不安全的决策。</li>
<li>论文提出了一种通过GP回归估计MPC参数的安全集合，以在RL更新过程中确保安全性。</li>
</ul></li>
<li><strong>方法论</strong>:
<ul>
<li><strong>MPC框架</strong>:
作为控制器，通过近似系统动态进行预测和优化。</li>
<li><strong>强化学习 (RL)</strong>: 调整MPC的参数以提高性能。</li>
<li><strong>高斯过程 (GP) 回归</strong>:
用于从数据中直接估计MPC参数的约束，预测某个参数是否会导致安全或不安全的策略。</li>
</ul></li>
<li><strong>关键贡献</strong>:
<ul>
<li>论文的创新点在于通过GP回归在RL过程中动态学习安全集合 (Safe
Set)。</li>
<li>通过概率约束的方式，确保学习过程中不会出现违反系统约束的情况。</li>
<li>与其他安全强化学习方法相比，该方法不需要对预测模型做过多的假设，提升了计算效率。</li>
</ul></li>
<li><strong>实验验证</strong>:
<ul>
<li>通过一个无人机控制实验验证了该方法的有效性。</li>
<li>结果显示，使用GP回归的安全强化学习方法在减少不安全的轨迹、加快收敛速度以及提高整体性能方面优于传统的RL方法。</li>
</ul></li>
<li><strong>优点与不足</strong>:
<ul>
<li><strong>优点</strong>:
通过数据驱动的方法提高安全性，并且避免了模型误差导致的控制失效。</li>
<li><strong>不足</strong>:
需要在早期阶段通过数据不断更新GP模型，并且在安全概率 (β)
的回退机制上存在一定的性能权衡。</li>
</ul></li>
<li><strong>未来工作</strong>:
<ul>
<li>解决因GP模型不准确导致的初期高不确定性问题。</li>
<li>将该方法扩展到更复杂的非线性和随机MPC框架中。</li>
</ul></li>
</ol>
<p>总结来说，这篇论文提出了一种创新性的基于GP的安全强化学习方法，通过对MPC参数的概率约束，实现了数据驱动的安全学习，大大减少了不安全行为的发生。</p>
<p>论文中的强化学习 (Reinforcement Learning, RL)
主要用于<strong>动态调整MPC控制器的参数</strong>，以<strong>提高系统性能</strong>，同时<strong>确保控制策略的安全性</strong>。具体过程如下：</p>
<hr />
<h2 id="强化学习目标">1. 强化学习目标</h2>
<p>强化学习的目标是通过不断交互和试探，<strong>找到最优的MPC参数
θ</strong>，使得在保持安全性的同时，最大化性能指标（或最小化损失函数）。</p>
<p>目标函数是： <span class="math display">\[
J(πθ)=Eτπθ[∑k=0∞γkL(sk,ak)]J(π_{\theta}) =
\mathbb{E}_{\tau_{\pi_{\theta}}} \left[ \sum_{k=0}^{\infty} \gamma^k
L(s_k, a_k) \right]
\]</span></p>
<ul>
<li><span class="math inline">\(\theta\)</span>
是MPC的参数（例如无人机的动力学参数）。</li>
<li><span class="math inline">\(L(sk,ak)L(s_k, a_k)\)</span>
是每个时间步的损失（如偏离目标位置或违反安全约束）。</li>
<li>γ是折扣因子。</li>
<li>τπθ<em>{</em>{}} 是当前MPC策略下的轨迹。</li>
</ul>
<hr />
<h2 id="强化学习如何更新mpc参数">2. 强化学习如何更新MPC参数</h2>
<p>论文采用了一种<strong>基于梯度更新的强化学习方法</strong>，例如Q-Learning或Policy
Gradient方法。</p>
<p>参数更新公式：</p>
<p><span class="math inline">\(θ←θ−α∇θ∑k=0mψ(sk,ak,sk+1,θ)\theta
\leftarrow \theta - \alpha \nabla_{\theta} \sum_{k=0}^{m} \psi(s_k, a_k,
s_{k+1}, \theta)\)</span></p>
<ul>
<li><span class="math inline">\(\alpha\)</span> 是学习率。</li>
<li><span class="math inline">\(\psi\)</span>
是强化学习损失项（例如Q-learning损失或策略梯度）。</li>
<li>mm 是观测批量（Batch size）。</li>
</ul>
<hr />
<h2 id="结合mpc的作用">3. 结合MPC的作用</h2>
<p>在本方法中，MPC不仅提供了控制信号，还作为<strong>强化学习的策略函数</strong>：</p>
<p><span class="math inline">\(πθ(s)=arg⁡min⁡uQθ(s,u)\pi_{\theta}(s) =
\arg \min_{u} Q_{\theta}(s, u)\)</span></p>
<ul>
<li>通过MPC的优化过程直接得到当前状态 ss 下的最优控制输入 uu。</li>
<li>强化学习通过**调整MPC中的参数 θ*，间接实现了策略的改进。</li>
</ul>
<hr />
<h2 id="安全性约束">4. 安全性约束</h2>
<p>由于强化学习过程中的探索可能导致<strong>违反安全约束</strong>，论文使用<strong>高斯过程
(GP) 回归</strong>来估计安全区域 SS，并限制强化学习的参数更新范围：</p>
<p><span
class="math inline">\(θ+=arg⁡min⁡θ12∥θ+−θ∥2+α∇θ∑k=0mψ(sk,ak,sk+1,θ)\theta^+
= \arg \min_{\theta} \frac{1}{2} \| \theta^+ - \theta \|^2 + \alpha
\nabla_{\theta} \sum_{k=0}^{m} \psi(s_k, a_k, s_{k+1},
\theta)\)</span></p>
<p>subject to: θ∈SD  S_D</p>
<p>其中，安全集合 SDS_D
是通过GP估计的“安全参数集合”，确保每次更新的MPC参数不会导致系统违反约束。</p>
<hr />
<h2 id="强化学习-安全机制的循环过程">5. 强化学习-安全机制的循环过程</h2>
<h3 id="强化学习循环">强化学习循环：</h3>
<ol type="1">
<li><strong>MPC控制器执行一轮任务 (Trajectory
Rollout)</strong>，收集状态-动作-奖励数据。</li>
<li><strong>计算当前MPC参数的安全性</strong>（是否违反了状态或控制约束）。</li>
<li><strong>GP回归模型更新安全区域</strong> SDS_D。</li>
<li>**强化学习更新MPC参数 θ*，同时确保参数更新受安全区域 SDS_D
限制。</li>
<li>**下一次MPC控制器使用新的参数 θ*，并重复上述过程。</li>
</ol>
<hr />
<h2 id="为什么引入强化学习">6. 为什么引入强化学习？</h2>
<ul>
<li><strong>MPC本身具有良好的控制性能</strong>，但在面对不确定性（如风扰动）和复杂环境时，需要不断<strong>在线调整参数</strong>。</li>
<li>强化学习提供了一种<strong>数据驱动的方式</strong>，通过多轮交互不断改进MPC参数。</li>
<li>传统RL算法容易出现探索导致安全性破坏的问题，而论文通过<strong>GP约束机制</strong>，确保在强化学习过程中不会发生安全约束的违反。</li>
</ul>
<hr />
<h2 id="总结">✅ 总结：</h2>
<h3 id="强化学习的角色">强化学习的角色：</h3>
<ol type="1">
<li>**通过调整MPC参数 θ*，不断提高控制性能；</li>
<li><strong>利用GP回归评估安全性</strong>，确保在探索过程中不会违反安全约束；</li>
<li><strong>数据驱动</strong> +
<strong>模型预测控制</strong>，实现了<strong>安全性保证</strong> +
<strong>性能优化</strong>的双重目标。</li>
</ol>
<hr />
<p>如果需要详细的图示解释或算法流程图，我可以帮你画出来！ 😊</p>
<p>论文中使用的强化学习方法是<strong>“基于最小二乘的Q学习 (LSTD
Q-Learning)”</strong>，具体来说是<strong>二阶LSTD Q-Learning
(Second-Order Least Squares Temporal Difference
Q-Learning)</strong>。</p>
<hr />
<h2 id="为什么使用-lstd-q-learning">✅ 为什么使用 LSTD Q-Learning？</h2>
<p>LSTD Q-Learning 是一种<strong>基于值函数 (Value-based)
的强化学习方法</strong>，相较于传统的Q-Learning，LSTD方法通过<strong>最小二乘回归</strong>直接拟合Q值函数，从而<strong>加快了学习速度</strong>，并且<strong>提高了数据效率</strong>。</p>
<hr />
<h2 id="强化学习目标-1">🎯 强化学习目标</h2>
<p>论文中的目标是通过调整MPC参数 θ，最小化以下目标函数：</p>
<p>J(πθ)=Eτπθ[∑k=0∞γkL(sk,ak)]J(π_{}) = <em>{</em>{_{}}} </p>
<ul>
<li>J(πθ)J(π_{}) 是累积损失；</li>
<li>L(sk,ak)L(s_k, a_k) 是每个时间步的损失
(如偏离目标位置、违反约束等)；</li>
<li>θ是MPC的可调参数；</li>
<li>γ是折扣因子。</li>
</ul>
<hr />
<h2 id="lstd-q-learning-的更新方式">🚀 LSTD Q-Learning 的更新方式</h2>
<h3 id="目标估计q值函数">💡 (1) 目标：估计Q值函数</h3>
<p>Qθ(s,a)=L(s,a)+γVθ(s′)Q_{}(s, a) = L(s, a) + V_{}(s')</p>
<h3 id="td误差-temporal-difference-error">💡 (2) TD误差 (Temporal
Difference Error)</h3>
<p>δ=L(s,a)+γVθ(s′)−Qθ(s,a)= L(s, a) + V_{}(s') - Q_{}(s, a)</p>
<h3 id="更新梯度和hessian矩阵">💡 (3) 更新梯度和Hessian矩阵</h3>
<p>p=−∑i=1mδi∇θQθ(si,ai)p = - <em>{i=1}^{m} <em>i </em>{} Q</em>{}(s_i,
a_i)</p>
<p>H=∑i=1m∇θQθ(si,ai)∇θQθ(si,ai)T−δi∇θ2Qθ(si,ai)H = <em>{i=1}^{m}
</em>{} Q_{}(s_i, a_i) <em>{} Q</em>{}(s_i, a_i)^T - <em>i ^2</em>{}
Q_{}(s_i, a_i)</p>
<ul>
<li>pp 是梯度方向；</li>
<li>HH 是近似Hessian矩阵；</li>
<li>mm 是观测批量 (Batch size)。</li>
</ul>
<h3 id="参数更新">💡 (4) 参数更新</h3>
<p>θ←θ+αH−1p+ H^{-1} p</p>
<hr />
<h2 id="强化学习-mpc-gp的完整流程">🔥 强化学习-MPC-GP的完整流程</h2>
<table>
<thead>
<tr>
<th>过程</th>
<th>方法</th>
</tr>
</thead>
<tbody>
<tr>
<td>策略 (Policy)</td>
<td>MPC控制器 (通过解最优控制问题得到动作 uu)</td>
</tr>
<tr>
<td>值函数 (Value)</td>
<td>LSTD Q-Learning 拟合Q值函数</td>
</tr>
<tr>
<td>安全性保证</td>
<td>高斯过程 (GP) 建模MPC参数的安全约束</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="为什么选用-lstd-q-learning">✅ 为什么选用 LSTD Q-Learning？</h2>
<table>
<thead>
<tr>
<th>优点</th>
<th>LSTD Q-Learning</th>
<th>传统Q-Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td>学习效率</td>
<td>高 (通过最小二乘法直接拟合)</td>
<td>低</td>
</tr>
<tr>
<td>数据利用率</td>
<td>高 (支持小批量学习)</td>
<td>依赖大量采样</td>
</tr>
<tr>
<td>收敛速度</td>
<td>快</td>
<td>慢</td>
</tr>
<tr>
<td>与MPC兼容性</td>
<td>强 (可以结合梯度更新MPC参数)</td>
<td>较弱</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="总结-1">🌟 总结</h2>
<p>论文选择 LSTD Q-Learning 是因为它：</p>
<ul>
<li>能够<strong>快速收敛</strong>；</li>
<li>能**直接通过梯度更新MPC参数 θ*；</li>
<li>能通过<strong>高斯过程 (GP) 回归确保安全性</strong>；</li>
<li>有效解决了传统RL中“安全性”和“数据效率”之间的矛盾。</li>
</ul>
<hr />
<p>我可以给你画一个完整的强化学习-MPC安全学习流程图，或者写一个Python实现的框架代码，你需要吗？
😊</p>
<h3 id="用一个具体的例子来解释-lstd-q-learning-的原理">🌟
用一个具体的例子来解释 LSTD Q-Learning 的原理：</h3>
<hr />
<h2 id="问题背景">🎯 <strong>问题背景</strong>：</h2>
<p>假设我们正在控制一架无人机
(Quadrotor)，目标是让无人机从起点飞到目标点，同时避开障碍物，并保持飞行稳定。</p>
<ul>
<li><strong>状态 ss</strong>：无人机的位置和速度</li>
<li><strong>动作 aa</strong>：无人机的推力和姿态角度</li>
<li><strong>奖励
rr</strong>：目标位置的接近程度，以及是否违反了安全约束</li>
<li>**MPC控制器参数 θ*：无人机的动力学参数（如重力常数 gg 和推力系数
KzK_z）</li>
</ul>
<hr />
<h2 id="传统q-learning的问题">✅
<strong>传统Q-Learning的问题</strong>：</h2>
<p>传统的Q-Learning使用的是“表格型”或者“神经网络”来估计Q值函数
Q(s,a)Q(s, a)，但：</p>
<ul>
<li><strong>收敛速度慢</strong></li>
<li><strong>需要大量的训练数据</strong></li>
<li><strong>无法处理连续状态和连续动作空间</strong></li>
</ul>
<hr />
<h2 id="lstd-q-learning的核心思路">🚀 <strong>LSTD
Q-Learning的核心思路</strong>：</h2>
<h3
id="直接用最小二乘法-least-squares-估计q值函数"><strong>直接用最小二乘法
(Least Squares) 估计Q值函数</strong>：</h3>
<p>目标：直接学习<strong>Q值函数的参数化表达</strong>：</p>
<p>Qθ(s,a)=ϕ(s,a)TθQ_{}(s, a) = (s, a)^T </p>
<ul>
<li>ϕ(s,a)(s, a) 是特征向量 (Feature
Vector)，比如无人机的位置、速度、姿态等；</li>
<li>θ是我们希望学习的MPC参数 (例如重力常数 gg、推力系数 KzK_z)。</li>
</ul>
<hr />
<h2 id="具体步骤">✅ <strong>具体步骤</strong>：</h2>
<hr />
<h2 id="第1步收集交互数据">🎯
<strong>第1步：收集交互数据</strong>：</h2>
<p>在第 tt 次飞行任务中，我们收集到了一条轨迹：</p>
<p>(st,at,rt,st+1)(s_t, a_t, r_t, s_{t+1})</p>
<ul>
<li>sts_t：当前状态（当前位置和速度）</li>
<li>ata_t：当前MPC控制器输出的推力</li>
<li>rtr_t：即时奖励 (Reward)，如到目标点的距离和违反约束的惩罚</li>
<li>st+1s_{t+1}：下一时刻的状态</li>
</ul>
<hr />
<h2 id="第2步计算td误差-temporal-difference-error">🎯
<strong>第2步：计算TD误差 (Temporal Difference Error)</strong>：</h2>
<p>δ=rt+γQθ(st+1,at+1)−Qθ(st,at)= r_t + Q_{}(s_{t+1}, a_{t+1}) -
Q_{}(s_t, a_t)</p>
<ul>
<li>γ是折扣因子 (Discount Factor)</li>
<li>Qθ(st+1,at+1)Q_{}(s_{t+1}, a_{t+1}) 是下一状态的估计Q值</li>
</ul>
<hr />
<h2 id="第3步lstd最小二乘更新">🎯
<strong>第3步：LSTD最小二乘更新</strong></h2>
<p>在传统Q-Learning中，我们使用的是：</p>
<p>θ←θ+αδ∇θQθ(st,at)+ <em>{} Q</em>{}(s_t, a_t)</p>
<p>但在LSTD Q-Learning中，我们不直接用梯度，而是<strong>用最小二乘法
(Least Squares) 直接拟合Q值函数</strong>。</p>
<hr />
<h3 id="核心公式">🔥 <strong>核心公式</strong>：</h3>
<p>Aθ=bA = b</p>
<ul>
<li>AA 是特征的协方差矩阵；</li>
<li>bb 是Q值目标与特征的相关性；</li>
</ul>
<hr />
<h3 id="矩阵形式">🌈 <strong>矩阵形式</strong>：</h3>
<p>A=∑t=1mϕ(st,at)(ϕ(st,at)−γϕ(st+1,at+1))TA = <em>{t=1}^{m} (s_t, a_t)
( (s_t, a_t) - (s</em>{t+1}, a_{t+1}) )^T</p>
<p>b=∑t=1mϕ(st,at)rtb = _{t=1}^{m} (s_t, a_t) r_t</p>
<hr />
<h3 id="解出最优参数">✅ <strong>解出最优参数</strong>：</h3>
<p>θ=A−1b= A^{-1} b</p>
<hr />
<h2 id="第4步mpc参数更新">🎯 <strong>第4步：MPC参数更新</strong></h2>
<p>在每一轮飞行任务之后，使用LSTD-Q学习到的参数 θ来更新MPC控制器：</p>
<p>θnew=θold−αH−1p<em>{new} = </em>{old} - H^{-1} p</p>
<ul>
<li>HH：近似Hessian矩阵</li>
<li>pp：梯度方向</li>
</ul>
<hr />
<h2 id="第5步引入高斯过程-gp-进行安全约束">🎯
<strong>第5步：引入高斯过程 (GP) 进行安全约束</strong></h2>
<p>通过高斯过程 (GP) 建模MPC参数 θ的安全区域：</p>
<p>θ∈SD={θ∣P[z(θ)≤0]≥β}S_D = { | P[z() ] }</p>
<hr />
<h2 id="最终效果">✅ <strong>最终效果</strong>：</h2>
<table>
<thead>
<tr>
<th>强化学习方法</th>
<th>学习速度</th>
<th>安全性</th>
<th>收敛速度</th>
</tr>
</thead>
<tbody>
<tr>
<td>传统Q-Learning</td>
<td>慢</td>
<td>无法保证</td>
<td>慢</td>
</tr>
<tr>
<td>LSTD Q-Learning + GP</td>
<td>快</td>
<td>高斯过程约束</td>
<td>快</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="完整流程图">🎁 <strong>完整流程图</strong>：</h2>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">+----------------------------+</span><br><span class="line">|     强化学习模块 (RL)       |</span><br><span class="line">|                            |</span><br><span class="line">|     LSTD Q-Learning        |</span><br><span class="line">|   更新MPC参数 θ            |</span><br><span class="line">+----------------------------+</span><br><span class="line">             ↓</span><br><span class="line">+----------------------------+</span><br><span class="line">|          MPC控制器            |</span><br><span class="line">|                            |</span><br><span class="line">|   min_u Q_θ(s, u)          |</span><br><span class="line">|   预测下一步控制动作 u      |</span><br><span class="line">+----------------------------+</span><br><span class="line">             ↓</span><br><span class="line">+----------------------------+</span><br><span class="line">|        系统环境                  |</span><br><span class="line">|                            |</span><br><span class="line">|   接收动作 u，反馈状态 s&#x27; |</span><br><span class="line">+----------------------------+</span><br></pre></td></tr></table></figure>
<hr />
<h2 id="总结-2">✅ <strong>总结</strong></h2>
<p>LSTD Q-Learning 的优点：</p>
<table>
<thead>
<tr>
<th>特点</th>
<th>传统Q-Learning</th>
<th>LSTD Q-Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td>学习速度</td>
<td>慢</td>
<td>快 (最小二乘法)</td>
</tr>
<tr>
<td>样本效率</td>
<td>低</td>
<td>高</td>
</tr>
<tr>
<td>收敛速度</td>
<td>慢</td>
<td>快</td>
</tr>
<tr>
<td>安全性保证</td>
<td>无</td>
<td>通过高斯过程 (GP)</td>
</tr>
</tbody>
</table>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" rel="tag"># 强化学习</a>
              <a href="/tags/MPC/" rel="tag"># MPC</a>
              <a href="/tags/safe-learning/" rel="tag"># safe_learning</a>
              <a href="/tags/%E6%8E%A7%E5%88%B6/" rel="tag"># 控制</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/03/11/hello-world/" rel="prev" title="Hello World">
      <i class="fa fa-chevron-left"></i> Hello World
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/03/18/%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/" rel="next" title="规划算法">
      规划算法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87"><span class="nav-number">1.</span> <span class="nav-text">1. 强化学习目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%A6%82%E4%BD%95%E6%9B%B4%E6%96%B0mpc%E5%8F%82%E6%95%B0"><span class="nav-number">2.</span> <span class="nav-text">2. 强化学习如何更新MPC参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%93%E5%90%88mpc%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">3.</span> <span class="nav-text">3. 结合MPC的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E6%80%A7%E7%BA%A6%E6%9D%9F"><span class="nav-number">4.</span> <span class="nav-text">4. 安全性约束</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BE%AA%E7%8E%AF%E8%BF%87%E7%A8%8B"><span class="nav-number">5.</span> <span class="nav-text">5. 强化学习-安全机制的循环过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%BE%AA%E7%8E%AF"><span class="nav-number">5.1.</span> <span class="nav-text">强化学习循环：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BC%95%E5%85%A5%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.</span> <span class="nav-text">6. 为什么引入强化学习？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">7.</span> <span class="nav-text">✅ 总结：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%A7%92%E8%89%B2"><span class="nav-number">7.1.</span> <span class="nav-text">强化学习的角色：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-lstd-q-learning"><span class="nav-number">8.</span> <span class="nav-text">✅ 为什么使用 LSTD Q-Learning？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9B%AE%E6%A0%87-1"><span class="nav-number">9.</span> <span class="nav-text">🎯 强化学习目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lstd-q-learning-%E7%9A%84%E6%9B%B4%E6%96%B0%E6%96%B9%E5%BC%8F"><span class="nav-number">10.</span> <span class="nav-text">🚀 LSTD Q-Learning 的更新方式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%AE%E6%A0%87%E4%BC%B0%E8%AE%A1q%E5%80%BC%E5%87%BD%E6%95%B0"><span class="nav-number">10.1.</span> <span class="nav-text">💡 (1) 目标：估计Q值函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#td%E8%AF%AF%E5%B7%AE-temporal-difference-error"><span class="nav-number">10.2.</span> <span class="nav-text">💡 (2) TD误差 (Temporal
Difference Error)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9B%B4%E6%96%B0%E6%A2%AF%E5%BA%A6%E5%92%8Chessian%E7%9F%A9%E9%98%B5"><span class="nav-number">10.3.</span> <span class="nav-text">💡 (3) 更新梯度和Hessian矩阵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="nav-number">10.4.</span> <span class="nav-text">💡 (4) 参数更新</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-mpc-gp%E7%9A%84%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B"><span class="nav-number">11.</span> <span class="nav-text">🔥 强化学习-MPC-GP的完整流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%80%89%E7%94%A8-lstd-q-learning"><span class="nav-number">12.</span> <span class="nav-text">✅ 为什么选用 LSTD Q-Learning？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-1"><span class="nav-number">13.</span> <span class="nav-text">🌟 总结</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%94%A8%E4%B8%80%E4%B8%AA%E5%85%B7%E4%BD%93%E7%9A%84%E4%BE%8B%E5%AD%90%E6%9D%A5%E8%A7%A3%E9%87%8A-lstd-q-learning-%E7%9A%84%E5%8E%9F%E7%90%86"><span class="nav-number">13.1.</span> <span class="nav-text">🌟
用一个具体的例子来解释 LSTD Q-Learning 的原理：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%97%AE%E9%A2%98%E8%83%8C%E6%99%AF"><span class="nav-number">14.</span> <span class="nav-text">🎯 问题背景：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9Fq-learning%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">15.</span> <span class="nav-text">✅
传统Q-Learning的问题：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#lstd-q-learning%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E8%B7%AF"><span class="nav-number">16.</span> <span class="nav-text">🚀 LSTD
Q-Learning的核心思路：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B4%E6%8E%A5%E7%94%A8%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95-least-squares-%E4%BC%B0%E8%AE%A1q%E5%80%BC%E5%87%BD%E6%95%B0"><span class="nav-number">16.1.</span> <span class="nav-text">直接用最小二乘法
(Least Squares) 估计Q值函数：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E6%AD%A5%E9%AA%A4"><span class="nav-number">17.</span> <span class="nav-text">✅ 具体步骤：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC1%E6%AD%A5%E6%94%B6%E9%9B%86%E4%BA%A4%E4%BA%92%E6%95%B0%E6%8D%AE"><span class="nav-number">18.</span> <span class="nav-text">🎯
第1步：收集交互数据：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC2%E6%AD%A5%E8%AE%A1%E7%AE%97td%E8%AF%AF%E5%B7%AE-temporal-difference-error"><span class="nav-number">19.</span> <span class="nav-text">🎯
第2步：计算TD误差 (Temporal Difference Error)：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC3%E6%AD%A5lstd%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%9B%B4%E6%96%B0"><span class="nav-number">20.</span> <span class="nav-text">🎯
第3步：LSTD最小二乘更新</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%A0%B8%E5%BF%83%E5%85%AC%E5%BC%8F"><span class="nav-number">20.1.</span> <span class="nav-text">🔥 核心公式：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E5%BD%A2%E5%BC%8F"><span class="nav-number">20.2.</span> <span class="nav-text">🌈 矩阵形式：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%A7%A3%E5%87%BA%E6%9C%80%E4%BC%98%E5%8F%82%E6%95%B0"><span class="nav-number">20.3.</span> <span class="nav-text">✅ 解出最优参数：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC4%E6%AD%A5mpc%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0"><span class="nav-number">21.</span> <span class="nav-text">🎯 第4步：MPC参数更新</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%AC%AC5%E6%AD%A5%E5%BC%95%E5%85%A5%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B-gp-%E8%BF%9B%E8%A1%8C%E5%AE%89%E5%85%A8%E7%BA%A6%E6%9D%9F"><span class="nav-number">22.</span> <span class="nav-text">🎯
第5步：引入高斯过程 (GP) 进行安全约束</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E7%BB%88%E6%95%88%E6%9E%9C"><span class="nav-number">23.</span> <span class="nav-text">✅ 最终效果：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E6%B5%81%E7%A8%8B%E5%9B%BE"><span class="nav-number">24.</span> <span class="nav-text">🎁 完整流程图：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93-2"><span class="nav-number">25.</span> <span class="nav-text">✅ 总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhicheng"
      src="/images/cheng.gif">
  <p class="site-author-name" itemprop="name">Zhicheng</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">21</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">29</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zhichengkou" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zhichengkou" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/weixin_46473460?type=blog" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;weixin_46473460?type&#x3D;blog" rel="noopener" target="_blank"><i class="fab fa-skype fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://scholar.google.com/citations?user=gMknN-8AAAAJ&hl=zh-CN&oi=ao" title="Google Scholar → https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user&#x3D;gMknN-8AAAAJ&amp;hl&#x3D;zh-CN&amp;oi&#x3D;ao" rel="noopener" target="_blank"><i class="fab fa-skype fa-fw"></i>Google Scholar</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://500px.com.cn/cheng1917" title="500px → https:&#x2F;&#x2F;500px.com.cn&#x2F;cheng1917" rel="noopener" target="_blank"><i class="fab fa-skype fa-fw"></i>500px</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhicheng</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>






<script data-pjax>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              leancloudSelector(url).innerText = 'Counter not initialized! More info at console err msg.';
              console.error('ATTENTION! LeanCloud counter has security bug, see how to solve it here: https://github.com/theme-next/hexo-leancloud-counter-security. \n However, you can still use LeanCloud without security, by setting `security` option to `false`.');
            
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":null,"app_key":null,"server_url":null,"security":true};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script>


      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="//cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script>
<script src="//cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script>
<script src="/js/algolia-search.js"></script>














    <div id="pjax">
  

  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout : 3000,
        priority: true,
        ignores : [uri => uri.includes('#'),uri => uri === 'http://zhichengkou.github.io/2025/03/18/safe-learning%E5%AE%9E%E8%B7%B5-%E5%9F%BA%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84MPC/',]
      });
      });
  </script>

    </div>
</body>
</html>
